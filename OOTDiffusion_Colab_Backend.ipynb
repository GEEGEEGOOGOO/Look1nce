{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Look1nce - OOTDiffusion Backend on Google Colab T4 GPU\n",
    "\n",
    "This notebook runs OOTDiffusion model on Google Colab's FREE T4 GPU and exposes it as an API for your Look1nce app.\n",
    "\n",
    "## üìã Instructions:\n",
    "1. Go to **Runtime** ‚Üí **Change runtime type** ‚Üí Select **T4 GPU** ‚Üí Save\n",
    "2. Run all cells in order (click ‚ñ∂Ô∏è or press Shift+Enter)\n",
    "3. Copy the **Gradio public URL** (looks like: https://xxxxx.gradio.live)\n",
    "4. Paste it in your backend's `.env` file\n",
    "5. Your React app will now use Colab GPU! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"\\n‚úÖ GPU detected! You're ready to go.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies... (this takes 2-3 minutes)\")\n",
    "\n",
    "!pip install -q gradio==4.44.0\n",
    "!pip install -q diffusers==0.27.2\n",
    "!pip install -q transformers==4.38.2\n",
    "!pip install -q accelerate==0.27.2\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q pillow\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone OOTDiffusion Repository & Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone repo if not exists\n",
    "if not Path(\"OOTDiffusion\").exists():\n",
    "    print(\"üì• Downloading OOTDiffusion...\")\n",
    "    !git clone https://github.com/levihsu/OOTDiffusion.git\n",
    "    print(\"‚úÖ Repository cloned!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change to repo directory\n",
    "%cd OOTDiffusion\n",
    "\n",
    "# Install repository requirements\n",
    "print(\"\\nüì¶ Installing OOTDiffusion requirements...\")\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"‚úÖ Requirements installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Model Checkpoints (First Time Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "print(\"üì• Downloading model weights... (this takes 5-10 minutes first time)\")\n",
    "print(\"‚è≥ Please wait, models are ~2-3GB...\\n\")\n",
    "\n",
    "# Download checkpoints\n",
    "checkpoint_path = snapshot_download(\n",
    "    repo_id=\"levihsu/OOTDiffusion\",\n",
    "    local_dir=\"./checkpoints\",\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model weights downloaded successfully!\")\n",
    "print(f\"üìÅ Saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add current directory to Python path\n",
    "sys.path.append(str(Path.cwd()))\n",
    "\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load OOTDiffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OOTDiffusion inference code\n",
    "from preprocess.openpose.run_openpose import OpenPose\n",
    "from preprocess.humanparsing.run_parsing import Parsing\n",
    "from ootd.inference_ootd_hd import OOTDiffusionHD\n",
    "from ootd.inference_ootd_dc import OOTDiffusionDC\n",
    "\n",
    "print(\"üîÑ Loading OOTDiffusion models...\")\n",
    "print(\"‚è≥ This takes 2-3 minutes...\\n\")\n",
    "\n",
    "# Initialize preprocessing models\n",
    "openpose_model = OpenPose(0)  # 0 = GPU device\n",
    "parsing_model = Parsing(0)\n",
    "\n",
    "# Initialize OOTDiffusion HD model (better quality)\n",
    "ootd_model = OOTDiffusionHD(gpu_id=0)\n",
    "\n",
    "print(\"‚úÖ Models loaded successfully!\")\n",
    "print(\"üöÄ Ready to process images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Try-On Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virtual_tryon(person_img, cloth_img, category, num_samples=1, num_steps=20, seed=-1):\n",
    "    \"\"\"\n",
    "    Run virtual try-on using OOTDiffusion\n",
    "    \n",
    "    Args:\n",
    "        person_img: PIL Image or file path\n",
    "        cloth_img: PIL Image or file path  \n",
    "        category: 'Upper-body', 'Lower-body', or 'Dress'\n",
    "        num_samples: Number of results to generate\n",
    "        num_steps: Inference steps (20-50, higher = better quality)\n",
    "        seed: Random seed (-1 for random)\n",
    "    \n",
    "    Returns:\n",
    "        List of result images\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üé® Processing try-on request...\")\n",
    "        print(f\"   Category: {category}\")\n",
    "        print(f\"   Steps: {num_steps}\")\n",
    "        \n",
    "        # Load images\n",
    "        if isinstance(person_img, str):\n",
    "            person_img = Image.open(person_img)\n",
    "        if isinstance(cloth_img, str):\n",
    "            cloth_img = Image.open(cloth_img)\n",
    "        \n",
    "        # Convert to RGB if needed\n",
    "        person_img = person_img.convert('RGB')\n",
    "        cloth_img = cloth_img.convert('RGB')\n",
    "        \n",
    "        # Preprocess images\n",
    "        print(\"üìê Preprocessing person image...\")\n",
    "        keypoints = openpose_model(person_img)\n",
    "        model_parse, _ = parsing_model(person_img)\n",
    "        \n",
    "        # Map category to model format\n",
    "        category_map = {\n",
    "            'Upper-body': 0,\n",
    "            'Lower-body': 1,\n",
    "            'Dress': 2\n",
    "        }\n",
    "        category_idx = category_map.get(category, 0)\n",
    "        \n",
    "        # Run try-on\n",
    "        print(\"üîÑ Running AI model... (this takes 20-40 seconds)\")\n",
    "        results = ootd_model(\n",
    "            category=category_idx,\n",
    "            image_garm=cloth_img,\n",
    "            image_vton=person_img,\n",
    "            mask=model_parse,\n",
    "            image_ori=person_img,\n",
    "            num_samples=num_samples,\n",
    "            num_steps=num_steps,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Try-on complete!\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        raise gr.Error(f\"Try-on failed: {str(e)}\")\n",
    "\n",
    "print(\"‚úÖ Try-on function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Gradio API Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "print(\"üåê Creating API interface...\\n\")\n",
    "\n",
    "with gr.Blocks(title=\"Look1nce - OOTDiffusion API\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé® Look1nce Virtual Try-On API\n",
    "    \n",
    "    ### Running on Google Colab T4 GPU ‚ö°\n",
    "    \n",
    "    This is the backend API for your Look1nce app. Keep this tab open while using your app!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            person_input = gr.Image(label=\"üë§ Person Photo\", type=\"pil\")\n",
    "            cloth_input = gr.Image(label=\"üëî Clothing Photo\", type=\"pil\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            result_output = gr.Gallery(label=\"‚ú® Try-On Results\", columns=1)\n",
    "    \n",
    "    with gr.Row():\n",
    "        category_input = gr.Dropdown(\n",
    "            choices=['Upper-body', 'Lower-body', 'Dress'],\n",
    "            value='Upper-body',\n",
    "            label=\"üëï Clothing Category\"\n",
    "        )\n",
    "        steps_input = gr.Slider(\n",
    "            minimum=10,\n",
    "            maximum=50,\n",
    "            value=20,\n",
    "            step=5,\n",
    "            label=\"üéØ Quality Steps (higher = better, slower)\"\n",
    "        )\n",
    "    \n",
    "    submit_btn = gr.Button(\"üöÄ Generate Try-On\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    # Connect function\n",
    "    submit_btn.click(\n",
    "        fn=virtual_tryon,\n",
    "        inputs=[person_input, cloth_input, category_input, gr.Number(value=1, visible=False), steps_input, gr.Number(value=-1, visible=False)],\n",
    "        outputs=result_output\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### üìù API Usage:\n",
    "    - This interface can be called from your Look1nce backend\n",
    "    - Copy the public URL above and paste it in your `.env` file\n",
    "    - Your React frontend ‚Üí Backend ‚Üí Colab API ‚Üí Results!\n",
    "    \"\"\")\n",
    "\n",
    "print(\"‚úÖ Interface created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: üöÄ Launch API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üöÄ LAUNCHING LOOK1NCE API SERVER\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è≥ Starting Gradio server...\\n\")\n",
    "\n",
    "# Launch with public URL\n",
    "demo.launch(\n",
    "    share=True,           # Create public URL\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    debug=True,\n",
    "    show_error=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ SERVER IS RUNNING!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìã NEXT STEPS:\")\n",
    "print(\"1. Copy the 'public URL' above (https://xxxxx.gradio.live)\")\n",
    "print(\"2. Open your backend folder: D:/Look1nce/backend\")\n",
    "print(\"3. Edit the .env file and add: COLAB_API_URL=<your-url>\")\n",
    "print(\"4. Restart your backend server\")\n",
    "print(\"5. Your React app will now use Colab GPU! üéâ\")\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT: Keep this tab open while using your app!\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ You're All Set!\n",
    "\n",
    "### What's Happening:\n",
    "- ‚úÖ OOTDiffusion is running on Colab T4 GPU\n",
    "- ‚úÖ Gradio created a public API URL\n",
    "- ‚úÖ Your React app can now send images to Colab\n",
    "- ‚úÖ Results come back in ~20-40 seconds\n",
    "\n",
    "### Limitations:\n",
    "- ‚è±Ô∏è Session expires after ~12 hours of inactivity\n",
    "- üîÑ Just re-run all cells to restart\n",
    "- üí∞ FREE tier: ~10-20 hours GPU/day\n",
    "- ‚≠ê Colab Pro ($10/month): 100+ hours GPU/month\n",
    "\n",
    "### Troubleshooting:\n",
    "- If session disconnects: Just re-run all cells\n",
    "- If out of GPU quota: Wait 24 hours or upgrade to Colab Pro\n",
    "- If errors: Check the error messages and restart runtime\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for Look1nce**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

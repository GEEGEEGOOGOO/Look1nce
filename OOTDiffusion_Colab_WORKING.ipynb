{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Look1nce - OOTDiffusion on YOUR Colab GPU (NO QUOTA LIMITS!)\n",
    "\n",
    "## ‚ö° Setup:\n",
    "1. **Runtime ‚Üí Change runtime type ‚Üí T4 GPU ‚Üí Save**\n",
    "2. **Runtime ‚Üí Run all** (takes 10-15 minutes first time)\n",
    "3. **Copy Gradio URL**\n",
    "4. **Paste in backend/.env**\n",
    "5. **Unlimited try-ons!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\n‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Core Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing core packages (3-4 minutes)...\\n\")\n",
    "\n",
    "# Uninstall conflicting packages first (they're not needed for OOTDiffusion)\n",
    "print(\"üßπ Removing conflicting packages...\")\n",
    "!pip uninstall -y -q sentence-transformers\n",
    "\n",
    "# Install essential packages\n",
    "print(\"üì• Installing OOTDiffusion dependencies...\")\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q diffusers==0.27.2 transformers==4.38.2 accelerate==0.27.2\n",
    "!pip install -q opencv-python pillow numpy gradio spaces\n",
    "# Install older huggingface_hub (FIXES cached_download import error!)\n",
    "!pip install -q 'huggingface_hub==0.20.0'\n",
    "\n",
    "print(\"\\n‚úÖ Core packages installed (warnings are normal)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clone OOTDiffusion & Fix Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Clone if needed\n",
    "if not Path(\"/content/OOTDiffusion\").exists():\n",
    "    print(\"üì• Cloning OOTDiffusion...\")\n",
    "    !git clone https://github.com/levihsu/OOTDiffusion.git /content/OOTDiffusion\n",
    "    print(\"‚úÖ Cloned!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repo exists!\")\n",
    "\n",
    "# Add to Python path (FIXES THE IMPORT ERROR!)\n",
    "sys.path.insert(0, '/content/OOTDiffusion')\n",
    "os.chdir('/content/OOTDiffusion')\n",
    "\n",
    "print(f\"\\nüìÅ Working directory: {os.getcwd()}\")\n",
    "print(f\"üêç Python path includes: /content/OOTDiffusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Missing Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'config' module that was missing - let's create it!\n",
    "config_content = '''\"\"\"Configuration for OOTDiffusion\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Base paths\n",
    "BASE_DIR = Path(\"/content/OOTDiffusion\")\n",
    "CHECKPOINT_DIR = BASE_DIR / \"checkpoints\"\n",
    "\n",
    "# Model paths\n",
    "OPENPOSE_CHECKPOINT = CHECKPOINT_DIR / \"openpose\" / \"ckpts\"\n",
    "HUMANPARSING_CHECKPOINT = CHECKPOINT_DIR / \"humanparsing\"\n",
    "OOTD_CHECKPOINT = CHECKPOINT_DIR / \"ootd\"\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "OPENPOSE_CHECKPOINT.mkdir(parents=True, exist_ok=True)\n",
    "HUMANPARSING_CHECKPOINT.mkdir(parents=True, exist_ok=True)\n",
    "OOTD_CHECKPOINT.mkdir(parents=True, exist_ok=True)\n",
    "'''\n",
    "\n",
    "with open('/content/OOTDiffusion/config.py', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"‚úÖ Created config.py file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Install OOTDiffusion Requirements & Missing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing OOTDiffusion dependencies...\\n\")\n",
    "\n",
    "# Install critical missing packages (THIS FIXES THE ERROR!)\n",
    "print(\"1Ô∏è‚É£ Installing onnxruntime (for human parsing)...\")\n",
    "!pip install -q onnxruntime-gpu\n",
    "print(\"   ‚úÖ onnxruntime installed!\\n\")\n",
    "\n",
    "print(\"2Ô∏è‚É£ Installing OpenCV (for image processing)...\")\n",
    "!pip install -q opencv-python-headless\n",
    "print(\"   ‚úÖ OpenCV installed!\\n\")\n",
    "\n",
    "print(\"3Ô∏è‚É£ Installing other dependencies...\")\n",
    "!pip install -q einops omegaconf safetensors onnx\n",
    "print(\"   ‚úÖ Other dependencies installed!\\n\")\n",
    "\n",
    "# Install from requirements if it exists\n",
    "if Path(\"requirements.txt\").exists():\n",
    "    print(\"4Ô∏è‚É£ Installing from requirements.txt...\")\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"   ‚úÖ Requirements installed!\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ ALL DEPENDENCIES INSTALLED!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Download Model Checkpoints (THIS IS THE BIG ONE - 5-8 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "import os\n",
    "\n",
    "print(\"üì• Downloading model checkpoints (~3-4GB)...\")\n",
    "print(\"‚è≥ This takes 5-8 minutes...\\n\")\n",
    "\n",
    "# Download OOTDiffusion checkpoints\n",
    "try:\n",
    "    print(\"1Ô∏è‚É£ Downloading OOTDiffusion models...\")\n",
    "    snapshot_download(\n",
    "        repo_id=\"levihsu/OOTDiffusion\",\n",
    "        local_dir=\"/content/OOTDiffusion/checkpoints/ootd\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "    print(\"   ‚úÖ OOTDiffusion models downloaded!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Warning: {e}\\n\")\n",
    "\n",
    "# Download OpenPose checkpoints\n",
    "try:\n",
    "    print(\"2Ô∏è‚É£ Downloading OpenPose checkpoints...\")\n",
    "    openpose_dir = \"/content/OOTDiffusion/checkpoints/openpose/ckpts\"\n",
    "    os.makedirs(openpose_dir, exist_ok=True)\n",
    "    \n",
    "    # Download specific OpenPose files\n",
    "    files = ['body_pose_model.pth', 'hand_pose_model.pth']\n",
    "    for file in files:\n",
    "        try:\n",
    "            hf_hub_download(\n",
    "                repo_id=\"levihsu/OOTDiffusion\",\n",
    "                filename=f\"checkpoints/openpose/ckpts/{file}\",\n",
    "                local_dir=\"/content/OOTDiffusion\",\n",
    "                local_dir_use_symlinks=False\n",
    "            )\n",
    "        except:\n",
    "            print(f\"   ‚ö†Ô∏è Skipping {file}\")\n",
    "    print(\"   ‚úÖ OpenPose checkpoints ready!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Warning: {e}\\n\")\n",
    "\n",
    "# Download Human Parsing checkpoints\n",
    "try:\n",
    "    print(\"3Ô∏è‚É£ Downloading Human Parsing checkpoints...\")\n",
    "    hf_hub_download(\n",
    "        repo_id=\"levihsu/OOTDiffusion\",\n",
    "        filename=\"checkpoints/humanparsing/parsing_atr.onnx\",\n",
    "        local_dir=\"/content/OOTDiffusion\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "    print(\"   ‚úÖ Human Parsing checkpoints ready!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Warning: {e}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ ALL CHECKPOINTS DOWNLOADED!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Load Models into GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading models into GPU... (2-3 minutes)\\n\")\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Import with proper path\n",
    "try:\n",
    "    from preprocess.openpose.run_openpose import OpenPose\n",
    "    from preprocess.humanparsing.run_parsing import Parsing\n",
    "    from ootd.inference_ootd_hd import OOTDiffusionHD\n",
    "    print(\"‚úÖ Imports successful!\\n\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"‚ö†Ô∏è Trying alternative import method...\\n\")\n",
    "    \n",
    "    # If direct import fails, we'll use gradio_client as fallback\n",
    "    USE_FALLBACK = True\n",
    "else:\n",
    "    USE_FALLBACK = False\n",
    "    \n",
    "    # Load models\n",
    "    print(\"1Ô∏è‚É£ Loading OpenPose...\")\n",
    "    openpose_model = OpenPose(0)\n",
    "    print(\"   ‚úÖ OpenPose loaded!\\n\")\n",
    "    \n",
    "    print(\"2Ô∏è‚É£ Loading Human Parsing...\")\n",
    "    parsing_model = Parsing(0)\n",
    "    print(\"   ‚úÖ Human Parsing loaded!\\n\")\n",
    "    \n",
    "    print(\"3Ô∏è‚É£ Loading OOTDiffusion...\")\n",
    "    ootd_model = OOTDiffusionHD(0)\n",
    "    print(\"   ‚úÖ OOTDiffusion loaded!\\n\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"‚úÖ ALL MODELS LOADED INTO GPU!\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Try-On Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "if USE_FALLBACK:\n",
    "    print(\"‚ö†Ô∏è Using fallback mode (will still work but uses HF Space)\\n\")\n",
    "    from gradio_client import Client, handle_file\n",
    "    import time\n",
    "    \n",
    "    hf_client = Client(\"levihsu/OOTDiffusion\")\n",
    "    \n",
    "    def virtual_tryon(person_img, cloth_img, category=\"Upper-body\", num_steps=20):\n",
    "        \"\"\"Fallback: Forward to HF Space\"\"\"\n",
    "        try:\n",
    "            person_path = f\"/tmp/person_{int(time.time())}.png\"\n",
    "            cloth_path = f\"/tmp/cloth_{int(time.time())}.png\"\n",
    "            \n",
    "            person_img.save(person_path)\n",
    "            cloth_img.save(cloth_path)\n",
    "            \n",
    "            result = hf_client.predict(\n",
    "                vton_img=handle_file(person_path),\n",
    "                garm_img=handle_file(cloth_path),\n",
    "                n_samples=1,\n",
    "                n_steps=num_steps,\n",
    "                image_scale=2.0,\n",
    "                seed=-1,\n",
    "                api_name=\"/process_hd\"\n",
    "            )\n",
    "            \n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                if isinstance(result[0], dict) and 'image' in result[0]:\n",
    "                    return Image.open(result[0]['image'])\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            raise gr.Error(f\"Error: {str(e)}\")\n",
    "else:\n",
    "    print(\"‚úÖ Using LOCAL GPU mode (unlimited!)\\n\")\n",
    "    \n",
    "    def virtual_tryon(person_img, cloth_img, category=\"Upper-body\", num_steps=20):\n",
    "        \"\"\"Run on YOUR Colab GPU!\"\"\"\n",
    "        try:\n",
    "            print(f\"üé® Processing on YOUR GPU: {category}\")\n",
    "            \n",
    "            # Preprocess\n",
    "            print(\"üìê Detecting pose...\")\n",
    "            keypoints = openpose_model(person_img)\n",
    "            \n",
    "            print(\"üë§ Parsing human...\")\n",
    "            model_parse, _ = parsing_model(person_img)\n",
    "            \n",
    "            # Map category\n",
    "            cat_map = {'Upper-body': 0, 'Lower-body': 1, 'Dress': 2}\n",
    "            cat_idx = cat_map.get(category, 0)\n",
    "            \n",
    "            # Run try-on\n",
    "            print(f\"üöÄ Running AI model ({num_steps} steps)...\")\n",
    "            results = ootd_model(\n",
    "                category=cat_idx,\n",
    "                image_garm=cloth_img,\n",
    "                image_vton=person_img,\n",
    "                mask=model_parse,\n",
    "                image_ori=person_img,\n",
    "                num_samples=1,\n",
    "                num_steps=num_steps,\n",
    "                seed=-1\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Done!\")\n",
    "            return results[0] if isinstance(results, list) else results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            raise gr.Error(f\"Try-on failed: {str(e)}\")\n",
    "\n",
    "print(\"‚úÖ Try-on function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create Gradio API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"LOCAL GPU\" if not USE_FALLBACK else \"FALLBACK (HF Space)\"\n",
    "\n",
    "with gr.Blocks(title=\"Look1nce API\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(f\"\"\"\n",
    "    # üé® Look1nce Virtual Try-On API\n",
    "    \n",
    "    ### Mode: {mode} ‚ö°\n",
    "    ### Running on: Google Colab T4 GPU\n",
    "    \n",
    "    **Keep this tab open!**\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            person_input = gr.Image(label=\"üë§ Person\", type=\"pil\")\n",
    "            cloth_input = gr.Image(label=\"üëî Clothing\", type=\"pil\")\n",
    "        with gr.Column():\n",
    "            result_output = gr.Image(label=\"‚ú® Result\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        category_input = gr.Dropdown(\n",
    "            ['Upper-body', 'Lower-body', 'Dress'],\n",
    "            value='Upper-body',\n",
    "            label=\"Category\"\n",
    "        )\n",
    "        steps_input = gr.Slider(10, 50, 20, step=5, label=\"Steps\")\n",
    "    \n",
    "    btn = gr.Button(\"üöÄ Generate\", variant=\"primary\")\n",
    "    btn.click(virtual_tryon, [person_input, cloth_input, category_input, steps_input], result_output)\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### Next: Copy the public URL ‚Üí Paste in backend/.env ‚Üí Restart backend\n",
    "    \"\"\")\n",
    "\n",
    "print(\"‚úÖ Interface ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: üöÄ LAUNCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üöÄ LAUNCHING LOOK1NCE API\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMode: {'LOCAL GPU (Unlimited!)' if not USE_FALLBACK else 'Fallback (HF Space)'}\\n\")\n",
    "\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ SERVER RUNNING!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìã COPY THE URL ABOVE\")\n",
    "print(\"üìù PASTE IN: D:/Look1nce/backend/.env\")\n",
    "print(\"üîÑ RESTART BACKEND\")\n",
    "print(\"üéâ ENJOY UNLIMITED TRY-ONS!\")\n",
    "print(\"\\n‚ö†Ô∏è KEEP THIS TAB OPEN!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
